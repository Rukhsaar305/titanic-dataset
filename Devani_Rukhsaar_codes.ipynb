{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On April 15, 1952, one of the most famous ship sank killing 1502 people. Life and death is all about luck but there are many more factors that played role. There were few group of people that were more likely to survive than others. In this Kaggle challenge our objective is to predict that factors that played role in making one group more fortunate than the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rukhsaar\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "test data\n",
      "    PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "#importing the data\n",
    "titanic_train_main = pd.read_csv(\"titanic/train.csv\")\n",
    "titanic_test_main = pd.read_csv(\"titanic/test.csv\")\n",
    "print(\"train data\\n\\n\", titanic_train_main.head())\n",
    "print(\"\\n\\ntest data\\n\", titanic_test_main.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Data\n",
    "We have two CSV file â€“ 1) Train data and 2) Test Data. The main difference between those two files are that the train data has the column survived and in the test data we need to predict that column survived. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the train data\n",
    "titanic_train_main.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data type\n",
      "\n",
      " PassengerId      int64\n",
      "Survived         int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n",
      "\n",
      "\n",
      "Test Data type\n",
      "\n",
      " PassengerId      int64\n",
      "Pclass           int64\n",
      "Name            object\n",
      "Sex             object\n",
      "Age            float64\n",
      "SibSp            int64\n",
      "Parch            int64\n",
      "Ticket          object\n",
      "Fare           float64\n",
      "Cabin           object\n",
      "Embarked        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# checking data types\n",
    "print(\"Train Data type\\n\\n\",titanic_train_main.dtypes)\n",
    "print(\"\\n\\nTest Data type\\n\\n\",titanic_test_main.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable is â€˜Survivedâ€™ which is Categorical. 1 means Survived and Zero indicated Not Survived. Lets looks at the Features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preprocessing:\n",
    "#### Step 1: \n",
    "Merge the train and test data: As we will be training on Train data and then testing on Test Data, we need to merge both the dataâ€™s to clean them on the same scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging train and test data using pd.concat\n",
    "titanic = pd.concat([titanic_train_main,titanic_test_main],axis =0,\n",
    "                    ignore_index=True)\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 2: Adding columns. \n",
    "Before we go for checking missing values or or anything I want to try my analysis by creating a new column named title to find out if there is any relationship between a persons title or rank example Mr, Mrs, Doc or not. It might be useful for us in finding the missing age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:            Survived\n",
      "title              \n",
      "Capt.           0.0\n",
      "Col.            1.0\n",
      "Don.            0.0\n",
      "Dona.           0.0\n",
      "Dr.             3.0\n",
      "Jonkheer.       0.0\n",
      "Lady.           1.0\n",
      "Major.          1.0\n",
      "Master.        23.0\n",
      "Miss.         127.0\n",
      "Mlle.           2.0\n",
      "Mme.            1.0\n",
      "Mr.            81.0\n",
      "Mrs.           99.0\n",
      "Ms.             1.0\n",
      "Rev.            0.0\n",
      "Sir.            1.0\n",
      "the             1.0\n"
     ]
    }
   ],
   "source": [
    "#Generating title\n",
    "titanic['title'] = titanic.Name.apply(lambda name: name.split(',')[1].split()[0])\n",
    "titanic.title.value_counts()\n",
    "titanic.head()\n",
    "title_survived = titanic[['Survived','title']].groupby(['title']).sum()\n",
    "print(\"title:\",title_survived)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "0               1       0.0       3   \n",
       "1               2       1.0       1   \n",
       "2               3       1.0       3   \n",
       "3               4       1.0       1   \n",
       "4               5       0.0       3   \n",
       "...           ...       ...     ...   \n",
       "1304         1305       NaN       3   \n",
       "1305         1306       NaN       1   \n",
       "1306         1307       NaN       3   \n",
       "1307         1308       NaN       3   \n",
       "1308         1309       NaN       3   \n",
       "\n",
       "                                                   Name     Sex   Age  SibSp  \\\n",
       "0                               Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                                Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                              Allen, Mr. William Henry    male  35.0      0   \n",
       "...                                                 ...     ...   ...    ...   \n",
       "1304                                 Spector, Mr. Woolf    male   NaN      0   \n",
       "1305                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
       "1306                       Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
       "1307                                Ware, Mr. Frederick    male   NaN      0   \n",
       "1308                           Peter, Master. Michael J    male   NaN      1   \n",
       "\n",
       "      Parch              Ticket      Fare Cabin Embarked  title  \n",
       "0         0           A/5 21171    7.2500   NaN        S    1.0  \n",
       "1         0            PC 17599   71.2833   C85        C    2.0  \n",
       "2         0    STON/O2. 3101282    7.9250   NaN        S    3.0  \n",
       "3         0              113803   53.1000  C123        S    2.0  \n",
       "4         0              373450    8.0500   NaN        S    1.0  \n",
       "...     ...                 ...       ...   ...      ...    ...  \n",
       "1304      0           A.5. 3236    8.0500   NaN        S    1.0  \n",
       "1305      0            PC 17758  108.9000  C105        C    2.0  \n",
       "1306      0  SOTON/O.Q. 3101262    7.2500   NaN        S    1.0  \n",
       "1307      0              359309    8.0500   NaN        S    1.0  \n",
       "1308      1                2668   22.3583   NaN        C    4.0  \n",
       "\n",
       "[1309 rows x 13 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining titles and mapping them\n",
    "title = {'Mr.':1, 'Mrs.':2, 'Miss.':3, 'Master.':4, 'Don.':5 , 'Rev.':5 , 'Dr.':5, 'Mme.':2,\n",
    "       'Ms.':3, 'Major.':5, 'Lady.':5, 'Sir.':5, 'Mlle.':5, 'Col.':5, 'Capt.':5, 'the':5,\n",
    "       'Jonkheer.':1 }\n",
    "titanic.title = titanic.title.map(title)\n",
    "\n",
    "titanic.title = titanic.title.fillna(2)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cd44aa2088>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking correlation between all the features\n",
    "titanic_corr = titanic.corr()\n",
    "sns.heatmap(titanic_corr, annot = True, cbar = True, cmap = \"twilight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above columns shows that the age and survived have -7% correlation where as P class and survived are inversely correlated. We also see that the title and Survived are 41% correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new column Family\n",
    "we also see that SibSp and Parch that is Parents, Sibblings and spouse all belong to a family. So we will go forward and combine the count of Sibling/Spouse and Parent/Children. This feature together might be important as if having a larger family was important to get a spot on life boat or being alone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a new column family and deleting parch and Sibsp\n",
    "titanic[\"Family\"] = titanic.Parch + titanic.SibSp + 1\n",
    "titanic = titanic.drop(columns = [\"SibSp\", \"Parch\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above visualization it is clear that there is a relation between Survival and title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId     0.000000\n",
       "Survived       31.932773\n",
       "Pclass          0.000000\n",
       "Name            0.000000\n",
       "Sex             0.000000\n",
       "Age            20.091673\n",
       "Ticket          0.000000\n",
       "Fare            0.076394\n",
       "Cabin          77.463713\n",
       "Embarked        0.152788\n",
       "title           0.000000\n",
       "Family          0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding percentage of null value in each column\n",
    "null_value = titanic.isnull().sum()/len(titanic)*100\n",
    "null_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Survived have 31.93% missing values which is because the test data doesnâ€™t have Survived column. Age has 20.09% missing values, Cabin have 77.46% and Embarked 0.15%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill the missing values and drop columns that are not necessary\n",
    "Let's drop PassengerId, Name as they are not necessary\n",
    "we will also drop cabin as it has 77.4% missing values and the rest 22.6% are not related in any way\n",
    "We will also be dropping ticket as it has number which is not related in any way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping passengerId, Name, Cabin and ticket\n",
    "titanic = titanic.drop(columns = [\"PassengerId\",\"Name\",\"Cabin\",\"Ticket\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Embarked has 0.15% of missing value, I will use mode to to fill it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    914\n",
       "C    270\n",
       "Q    123\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the sum of counts of Embarked\n",
    "titanic.Embarked.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as S occurs the highest number of time, we will use S \n",
    "titanic.Embarked = titanic.Embarked.fillna(\"S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables: \n",
    "we will be creating dummy variables for all categorical variables as the algorithm can take only numbers and letters. We will use pandas pd.get_dummies() to convert Sex, Embarked, Pclass and title to dummy variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dummy variable for sex embarkked p class nad title\n",
    "titanic = pd.get_dummies(titanic, columns = [\"Sex\",\"Embarked\",\"Pclass\",\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping one column from the dummies created\n",
    "titanic = titanic.drop(columns = [\"Embarked_Q\",\"Pclass_1\",\"Sex_female\",\"title_5.0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values for age\n",
    "Rather than using mean, from the above correlation it shows that Age is highly negatively correlated with Pclass.It is also dependent on age and title. We will group them and use median to predict the age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried 2 analysis for predicting age. One I filled age using median and the other one age using KNN. I will be attaching results for both but my KNN gave me better result then Median. I have also attached code for median\n",
    "#titanicgroupage = titanic.groupby([\"Sex\",\"Pclass\",\"title\"])\n",
    "#titanicgroupage.Age.median()\n",
    "#titanic.Age = titanicgroupage.Age.apply(lambda x:x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value for Fare\n",
    "Fare having only 0.7% of missing data, Fare can also be predicted using KNN. But to KNN first we need to have all data as numerical. It can't take Male/Female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using knn imputer to fill the null values\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "titanicpd = imputer.fit_transform(titanic)\n",
    "titanic = pd.DataFrame(titanicpd, columns = titanic.columns)\n",
    "titanic = titanic.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are creating a creating a fuction to split the data into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data): #creating function for train\n",
    "    train = data.iloc[:891,:]\n",
    "    return train\n",
    "def test(data): #creating function for test\n",
    "    test = data.iloc[891:,:]\n",
    "    test = test.drop(columns = \"Survived\")\n",
    "    return test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Data to create a model\n",
    "We will create different sets of data on which we will train our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titanic1 \n",
    "In this data type we will standardize Age, Fare and Family columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Family</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>title_1.0</th>\n",
       "      <th>title_2.0</th>\n",
       "      <th>title_3.0</th>\n",
       "      <th>title_4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.595809</td>\n",
       "      <td>-0.499677</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.540263</td>\n",
       "      <td>0.737458</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.311791</td>\n",
       "      <td>-0.499677</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.327250</td>\n",
       "      <td>0.389514</td>\n",
       "      <td>0.073352</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.327250</td>\n",
       "      <td>-0.480347</td>\n",
       "      <td>-0.558346</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived       Age      Fare    Family  Sex_male  Embarked_C  Embarked_S  \\\n",
       "0         0 -0.595809 -0.499677  0.073352         1           0           1   \n",
       "1         1  0.540263  0.737458  0.073352         0           1           0   \n",
       "2         1 -0.311791 -0.499677 -0.558346         0           0           1   \n",
       "3         1  0.327250  0.389514  0.073352         0           0           1   \n",
       "4         0  0.327250 -0.480347 -0.558346         1           0           1   \n",
       "\n",
       "   Pclass_2  Pclass_3  title_1.0  title_2.0  title_3.0  title_4.0  \n",
       "0         0         1          1          0          0          0  \n",
       "1         0         0          0          1          0          0  \n",
       "2         0         1          0          0          1          0  \n",
       "3         0         0          0          1          0          0  \n",
       "4         0         1          1          0          0          0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Titanic1 = titanic.copy()\n",
    "col_names = [\"Age\",\"Fare\",\"Family\"]\n",
    "features = Titanic1[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "Titanic1[col_names] = features\n",
    "Titanic1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing the data into train and test\n",
    "titanic1_train = train(Titanic1)\n",
    "titanic1_test = test(Titanic1)\n",
    "titanic1_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic2\n",
    "In this we are not going to normalize the data. It is the same data as titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used data without normalization. So no need to pre process. Just change it into train and test\n",
    "titanic2 = titanic.copy()\n",
    "titanic2_train = train(titanic2)\n",
    "titanic2_test = test(titanic2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic 3\n",
    "In this we will use ISOMAP for Dimesnion reduction. We will set the n components as 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>-21.979981</td>\n",
       "      <td>-0.646153</td>\n",
       "      <td>9.375414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>-23.678811</td>\n",
       "      <td>-2.175473</td>\n",
       "      <td>23.669549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>-24.993206</td>\n",
       "      <td>-4.262507</td>\n",
       "      <td>36.201751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>-22.895129</td>\n",
       "      <td>-0.491196</td>\n",
       "      <td>2.824839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-18.273659</td>\n",
       "      <td>0.550595</td>\n",
       "      <td>-8.122668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>-24.243047</td>\n",
       "      <td>-0.560662</td>\n",
       "      <td>-1.762583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>20.768355</td>\n",
       "      <td>4.411655</td>\n",
       "      <td>1.382773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>-21.852895</td>\n",
       "      <td>-0.896259</td>\n",
       "      <td>13.575859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>-24.243047</td>\n",
       "      <td>-0.560662</td>\n",
       "      <td>-1.762583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>-4.907273</td>\n",
       "      <td>2.217874</td>\n",
       "      <td>-24.085862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1          2\n",
       "891  -21.979981 -0.646153   9.375414\n",
       "892  -23.678811 -2.175473  23.669549\n",
       "893  -24.993206 -4.262507  36.201751\n",
       "894  -22.895129 -0.491196   2.824839\n",
       "895  -18.273659  0.550595  -8.122668\n",
       "...         ...       ...        ...\n",
       "1304 -24.243047 -0.560662  -1.762583\n",
       "1305  20.768355  4.411655   1.382773\n",
       "1306 -21.852895 -0.896259  13.575859\n",
       "1307 -24.243047 -0.560662  -1.762583\n",
       "1308  -4.907273  2.217874 -24.085862\n",
       "\n",
       "[418 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "titanic3 = titanic.copy()\n",
    "X = titanic3.drop(columns = \"Survived\")\n",
    "y = titanic3[\"Survived\"]\n",
    "iso = Isomap(n_components=3)\n",
    "titanic3= iso.fit_transform(X)\n",
    "titanic3 = pd.DataFrame(titanic3)\n",
    "titanic3[\"Survived\"] = y\n",
    "titanic3_train = train(titanic3)\n",
    "titanic3_test = test(titanic3)\n",
    "titanic3_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic 4\n",
    "In this we will use TSNE for dimension reduction.\n",
    "from sklearn.manifold import Isomap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic4 = titanic.copy()\n",
    "X = titanic4.drop(columns = \"Survived\")\n",
    "y = titanic4[\"Survived\"]\n",
    "tsne = TSNE(n_components=3)\n",
    "titanic4= iso.fit_transform(X)\n",
    "titanic4 = pd.DataFrame(titanic4)\n",
    "titanic4[\"Survived\"] = y\n",
    "titanic4_train = train(titanic4)\n",
    "titanic4_test = test(titanic4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic 5\n",
    "In this data I converted age to categories. I divided it into 4 group 0-18, 19-35, 36-65 and 65 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cat = titanic.copy()\n",
    "titanic_cat[\"age_cat\"] = 4\n",
    "titanic_cat.loc[(titanic_cat[\"Age\"] >=0) & (titanic_cat[\"Age\"] <=18),\"age_cat\"] = 1\n",
    "titanic_cat.loc[(titanic_cat[\"Age\"] >=19) & (titanic_cat[\"Age\"] <=35),\"age_cat\"] = 2\n",
    "titanic_cat.loc[(titanic_cat[\"Age\"] >=36) & (titanic_cat[\"Age\"] <=65),\"age_cat\"] = 3\n",
    "titanic_cat = titanic_cat.drop(columns = \"Age\")\n",
    "titanic_cat = pd.get_dummies(titanic_cat, columns = [\"age_cat\"])\n",
    "titanic_cat = titanic_cat.drop(columns =\"age_cat_4\")\n",
    "titanic_cat_train = train(titanic_cat)\n",
    "titanic_cat_test = test(titanic_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic 6\n",
    "In this data we will use the age column that we converted into category and standardize the Fare and Family column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_cat_stand = titanic_cat.copy()\n",
    "col_names = [\"Fare\",\"Family\"]\n",
    "features = titanic_cat_stand[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "titanic_cat_stand[col_names] = features\n",
    "titanic_cat_stand.head()\n",
    "titanic_cat_stand_train = train(titanic_cat_stand)\n",
    "titanic_cat_stand_test = test(titanic_cat_stand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Algorithms to run it under different data sets\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logregmodel(X, y):\n",
    "    model = LogisticRegression(solver = \"liblinear\", random_state = 0)\n",
    "    accuracy_logreg = cross_val_score(model,X,y, cv =10,scoring = \"accuracy\")\n",
    "    return accuracy_logreg, np.mean(accuracy_logreg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(X, y):\n",
    "    KNN_model = KNeighborsClassifier()\n",
    "    param_grid = {'n_neighbors': [1,2,3,4,5,6]}\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    grid = GridSearchCV(KNN_model, param_grid, cv = cv, scoring='accuracy',\n",
    "                        return_train_score=False)\n",
    "    grid.fit(X,y)\n",
    "    print(\"Best Parameter: {}\".format(grid.best_params_))\n",
    "    print(\"Best Cross Vlidation Score: {}\".format(grid.best_score_))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data(X, y):\n",
    "    param_grid = {'C': [.1, 1, 5, 10, 50],\n",
    "                  'gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
    "                   'kernel': [\"rbf\",\"linear\"]}\n",
    "    svc = SVC()\n",
    "    \n",
    "    grid = GridSearchCV(svc, param_grid, cv = 5, scoring='accuracy')\n",
    "    grid.fit(X, y)\n",
    "    print(grid.best_params_)\n",
    "    print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dectree(X,y):\n",
    "    param_grid = {\"min_samples_leaf\":[2,3,4,5],\n",
    "                 \"max_depth\":[3,4,5,6,7,8,10],\n",
    "                 \"criterion\": [\"gini\",\"entropy\"]}\n",
    "\n",
    "    model = DecisionTreeClassifier()\n",
    "    grid = GridSearchCV(model,param_grid,scoring = \"accuracy\")\n",
    "    grid.fit(X,y)\n",
    "    print(\"Grid best parameters\",grid.best_params_)\n",
    "    print(\"grid best score\",grid.best_score_)\n",
    "    print(\"Tree best estimator\", grid.best_estimator_)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RanFor(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,random_state=0)\n",
    "    n = [10,30,50,100,200,500]\n",
    "    for i in n:\n",
    "        model = RandomForestClassifier(n_estimators = i, random_state = 0, min_samples_leaf = 3)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        acc_ranfor = accuracy_score(y_test,y_test_hat, normalize = True) * 100 \n",
    "        print(\"accuracy score with n =\",i,\",\", acc_ranfor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allalgo(data):\n",
    "    X = data.drop(columns = [\"Survived\"])\n",
    "    y = data[\"Survived\"]\n",
    "   \n",
    "    print(\"Logistic Regression\\n\\n\")\n",
    "    print(logregmodel(X,y))\n",
    "    print(\"\\n\\nKNN Model\\n\\n\")\n",
    "    print(KNN(X, y))\n",
    "    print(\"\\n\\nSVC Model\\n\\n\")\n",
    "    print(model_data(X,y))\n",
    "    print(\"\\n\\nClassification tree Model\\n\\n\")\n",
    "    print(Dectree(X, y))\n",
    "    print(\"\\n\\nRandom Forest\\n\\n\")\n",
    "    return RanFor(X, y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on Normalized data - Titanic 1\n",
    " we have functiosn saved above. Lets call them for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.81111111, 0.85393258, 0.7752809 , 0.87640449, 0.80898876,\n",
      "       0.79775281, 0.82022472, 0.82022472, 0.85393258, 0.87640449]), 0.8294257178526843)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 5}\n",
      "Best Cross Vlidation Score: 0.8248697508003264\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 50, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "0.8349946644906158\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 3}\n",
      "grid best score 0.8361496453455526\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 82.08955223880598\n",
      "accuracy score with n = 30 , 82.46268656716418\n",
      "accuracy score with n = 50 , 81.71641791044776\n",
      "accuracy score with n = 100 , 81.34328358208955\n",
      "accuracy score with n = 200 , 81.71641791044776\n",
      "accuracy score with n = 500 , 81.71641791044776\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on Regular data - Titanic 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.83333333, 0.85393258, 0.7752809 , 0.86516854, 0.82022472,\n",
      "       0.78651685, 0.82022472, 0.82022472, 0.85393258, 0.86516854]), 0.8294007490636706)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 3}\n",
      "Best Cross Vlidation Score: 0.7351704224468019\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.8305065595380077\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 3}\n",
      "grid best score 0.8361496453455526\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 82.08955223880598\n",
      "accuracy score with n = 30 , 82.46268656716418\n",
      "accuracy score with n = 50 , 81.71641791044776\n",
      "accuracy score with n = 100 , 81.34328358208955\n",
      "accuracy score with n = 200 , 81.71641791044776\n",
      "accuracy score with n = 500 , 81.71641791044776\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on ISOMAP - Titanic 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.54444444, 0.56179775, 0.65168539, 0.65168539, 0.64044944,\n",
      "       0.73033708, 0.70786517, 0.68539326, 0.68539326, 0.6741573 ]), 0.6533208489388265)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 3}\n",
      "Best Cross Vlidation Score: 0.7227732094658214\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 10, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "0.6847404431611324\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'gini', 'max_depth': 6, 'min_samples_leaf': 5}\n",
      "grid best score 0.6959073504488105\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=6, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=5, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 73.13432835820896\n",
      "accuracy score with n = 30 , 72.38805970149254\n",
      "accuracy score with n = 50 , 72.38805970149254\n",
      "accuracy score with n = 100 , 72.01492537313433\n",
      "accuracy score with n = 200 , 72.38805970149254\n",
      "accuracy score with n = 500 , 72.01492537313433\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic3_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on TSNE - Titanic 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.54444444, 0.56179775, 0.65168539, 0.65168539, 0.64044944,\n",
      "       0.73033708, 0.70786517, 0.68539326, 0.68539326, 0.6741573 ]), 0.6533208489388265)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 3}\n",
      "Best Cross Vlidation Score: 0.7216496139602033\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 10, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "0.6847404431611324\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'entropy', 'max_depth': 7, 'min_samples_leaf': 2}\n",
      "grid best score 0.697074885443475\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=2, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 73.13432835820896\n",
      "accuracy score with n = 30 , 72.38805970149254\n",
      "accuracy score with n = 50 , 72.38805970149254\n",
      "accuracy score with n = 100 , 72.01492537313433\n",
      "accuracy score with n = 200 , 72.38805970149254\n",
      "accuracy score with n = 500 , 72.01492537313433\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic4_train) # we have this functions saved above. Lets call them for each data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on Age as Categorical - Titanic 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.8       , 0.85393258, 0.7752809 , 0.88764045, 0.80898876,\n",
      "       0.80898876, 0.82022472, 0.83146067, 0.86516854, 0.86516854]), 0.8316853932584269)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 5}\n",
      "Best Cross Vlidation Score: 0.7912183792605612\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.8327537505492437\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 3}\n",
      "grid best score 0.8215805661917017\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=3, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 82.46268656716418\n",
      "accuracy score with n = 30 , 84.32835820895522\n",
      "accuracy score with n = 50 , 84.70149253731343\n",
      "accuracy score with n = 100 , 85.07462686567165\n",
      "accuracy score with n = 200 , 85.07462686567165\n",
      "accuracy score with n = 500 , 86.56716417910447\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic_cat_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above models we can see that the best Logistic Regression accuracy score is for Data titanic1 but for titanic_cat also the highest accuracy score is 88. So we will go with both. (77.6, 77.9)\n",
    "Best KNN Model is for titanic1 with 81.4% accuracy (77.03)\n",
    "Best SVC Model we will be running all teh 3 data's Titanic1, titanic2, titanic_cat\n",
    "For Classification tree also we will be running all the above mentioned 3 models\n",
    "For Random forest we will be running titanic_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all Algorithms on Categorical and Standardized data - Titanic 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "\n",
      "\n",
      "(array([0.81111111, 0.85393258, 0.7752809 , 0.88764045, 0.80898876,\n",
      "       0.79775281, 0.82022472, 0.83146067, 0.86516854, 0.86516854]), 0.8316729088639201)\n",
      "\n",
      "\n",
      "KNN Model\n",
      "\n",
      "\n",
      "Best Parameter: {'n_neighbors': 4}\n",
      "Best Cross Vlidation Score: 0.8215491808423827\n",
      "None\n",
      "\n",
      "\n",
      "SVC Model\n",
      "\n",
      "\n",
      "{'C': 50, 'gamma': 0.005, 'kernel': 'rbf'}\n",
      "0.8361182599962339\n",
      "None\n",
      "\n",
      "\n",
      "Classification tree Model\n",
      "\n",
      "\n",
      "Grid best parameters {'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 4}\n",
      "grid best score 0.8215805661917017\n",
      "Tree best estimator DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
      "                       max_depth=4, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=4, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best')\n",
      "None\n",
      "\n",
      "\n",
      "Random Forest\n",
      "\n",
      "\n",
      "accuracy score with n = 10 , 82.46268656716418\n",
      "accuracy score with n = 30 , 84.32835820895522\n",
      "accuracy score with n = 50 , 85.07462686567165\n",
      "accuracy score with n = 100 , 85.44776119402985\n",
      "accuracy score with n = 200 , 85.44776119402985\n",
      "accuracy score with n = 500 , 86.56716417910447\n"
     ]
    }
   ],
   "source": [
    "allalgo(titanic_cat_stand_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle accuracy is 79.4\n"
     ]
    }
   ],
   "source": [
    "logreg_model1 = LogisticRegression(solver='liblinear',random_state =0)\n",
    "logreg_model1.fit(titanic1_train.drop(columns = \"Survived\"),titanic1_train[\"Survived\"])\n",
    "y_test_hat = logreg_model1.predict(titanic1_test)\n",
    "y_test_hat = y_test_hat.astype(int)\n",
    "submit = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat})\n",
    "submit.to_csv(\"submit_logtitanic1.csv\", index=False)\n",
    "print(\"Kaggle accuracy is 79.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle accuracy is 78.4\n"
     ]
    }
   ],
   "source": [
    "svc_titanic1 = SVC(kernel = \"linear\",C=5, gamma= 0.0001)\n",
    "svc_titanic1.fit(titanic1_train.drop(columns = \"Survived\"),titanic1_train[\"Survived\"])\n",
    "y_test_hat3 = svc_titanic1.predict(titanic1_test)\n",
    "y_test_hat3 = y_test_hat3.astype(int)\n",
    "submit = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat3})\n",
    "submit.to_csv(\"submit_svc.csv\", index=False)\n",
    "print(\"Kaggle accuracy is 78.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_titanic1 = SVC(kernel = \"linear\",C=5, gamma= 0.0001)\n",
    "svc_titanic1.fit(titanic1_train.drop(columns = \"Survived\"),titanic1_train[\"Survived\"])\n",
    "y_test_hat3 = svc_titanic1.predict(titanic1_test)\n",
    "y_test_hat3 = y_test_hat3.astype(int)\n",
    "submit = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat3})\n",
    "submit.to_csv(\"submit_svc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle accuracy is 78.4%\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth= 5, min_samples_leaf = 2)\n",
    "model.fit(titanic1_train.drop(columns = \"Survived\"),titanic1_train[\"Survived\"])\n",
    "y_test_hat3 = svc_titanic1.predict(titanic1_test)\n",
    "y_test_hat3 = y_test_hat3.astype(int)\n",
    "submittree = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat3})\n",
    "submittree.to_csv(\"submit_tree.csv\", index=False)\n",
    "print(\"Kaggle accuracy is 78.4%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_modelcat = LogisticRegression(solver='liblinear',random_state =0)\n",
    "logreg_modelcat.fit(titanic_cat_train.drop(columns = \"Survived\"),titanic_cat_train[\"Survived\"])\n",
    "y_test_hat1 = logreg_modelcat.predict(titanic_cat_test)\n",
    "y_test_hat1 = y_test_hat1.astype(int)\n",
    "submitcat = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat1})\n",
    "submitcat.to_csv(\"submit_logtitaniccat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle accuracy 80.3%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 500, random_state = 0, min_samples_leaf = 3)\n",
    "model.fit(titanic_cat_train.drop(columns = \"Survived\"),titanic_cat_train[\"Survived\"])\n",
    "y_test_hat = model.predict(titanic_cat_test)\n",
    "y_test_hat = y_test_hat.astype(int)\n",
    "submit_cat_ranforest5001 = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat})\n",
    "submit_cat_ranforest5001.to_csv(\"submit_catfor5001.csv\", index=False)\n",
    "print(\"Kaggle accuracy 80.3%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle accuracy 79.4\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 200, random_state = 0, min_samples_leaf = 3)\n",
    "model.fit(titanic_cat_stand_train.drop(columns = \"Survived\"),titanic_cat_stand_train[\"Survived\"])\n",
    "y_test_hat = model.predict(titanic_cat_stand_test)\n",
    "y_test_hat = y_test_hat.astype(int)\n",
    "submit_cat_ranforest2001 = pd.DataFrame({'PassengerId' : titanic_test_main[\"PassengerId\"],\n",
    "                       'Survived': y_test_hat})\n",
    "submit_cat_ranforest2001.to_csv(\"submit_catfor2001.csv\", index=False)\n",
    "print(\"Kaggle accuracy 79.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
